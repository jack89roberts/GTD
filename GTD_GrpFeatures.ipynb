{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# columns of interest\n",
    "cols_to_extract = ['imonth', 'iyear','iday',\n",
    " 'country_txt','gname','attacktype1_txt',\n",
    " 'success','suicide',\n",
    " 'weaptype1_txt','weapsubtype1_txt',\n",
    " 'targtype1_txt','targsubtype1_txt',\n",
    " 'individual','nperps','claimed',\n",
    " 'nkill','nwound',\n",
    " 'property','propextent_txt',\n",
    " 'ishostkid','nhostkid','hostkidoutcome_txt','ransom']\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel('GTD_0617dist/globalterrorismdb_0617dist.xlsx',\n",
    "                   usecols=cols_to_extract,\n",
    "                   na_values = ['Unknown','-99','-9','Not Applicable'])\n",
    "\n",
    "# replace some values not correctly dealt with by pandas import\n",
    "df.replace(-9,np.nan,inplace=True)\n",
    "df.replace(-99,np.nan,inplace=True)\n",
    "\n",
    "# entries without month or day - treat as 1st January\n",
    "df['imonth'].replace(0,1,inplace=True)\n",
    "df['iday'].replace(0,1,inplace=True)\n",
    "\n",
    "# create a date column, then get rid of the month and day columns\n",
    "df['date']=pd.to_datetime(dict(year=df.iyear, month=df.imonth, day=df.iday)) \n",
    "df.rename(columns={'iyear':'year'}, inplace=True)\n",
    "df.drop(['imonth','iday'],axis=1,inplace=True)\n",
    "\n",
    "# set date as the index\n",
    "df.set_index('date',inplace=True)\n",
    "\n",
    "# If no claimed info - treat as not claimed\n",
    "df['claimed'].fillna(0,inplace=True)\n",
    "\n",
    "display(df.head(5))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove events with no group affiliation\n",
    "no_grp = df.gname.isnull() | df.individual\n",
    "with_grp = ~no_grp\n",
    "df = df[with_grp]\n",
    "\n",
    "# don't need the 'individual' column any more\n",
    "df.drop('individual',axis=1,inplace=True)\n",
    "\n",
    "# only keep the top n groups with the most incidents\n",
    "n_groups = df['gname'].nunique() #100 #df['gname'].nunique() for all groups\n",
    "top_grps = df['gname'].value_counts().head(n_groups).index\n",
    "df = df[df.gname.isin(top_grps)]\n",
    "\n",
    "print('Number of events affiliated with individuals or unknown group: ',sum(no_grp))\n",
    "print('Number of events affiliated with a group: ',sum(with_grp))\n",
    "print('Number of events affiliated with top 100 groups: ',len(df))\n",
    "print('')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorise some columns to help feature extraction later\n",
    "\n",
    "# Numeric columns - convert to values for 0, 1, 2-10, and more than 10 \n",
    "conv_numeric = ['nkill','nwound','nperps','nhostkid']\n",
    "\n",
    "for col in conv_numeric:\n",
    "    df[col] = pd.cut(df[col],\n",
    "                        [-0.1,0.9,1.9,10.9,max(df[col])+0.1],\n",
    "                        labels=['0_'+col,'1_'+col,'2to10_'+col,'11+_'+col])\n",
    "\n",
    "# boolean columns - add column suffix\n",
    "conv_bool = ['success','suicide','claimed','ishostkid','ransom','property']\n",
    "\n",
    "for col in conv_bool:\n",
    "    df[col].replace({0:('0_'+col),1:('1_'+col)},inplace=True)\n",
    "\n",
    "# bin year in to decades\n",
    "df['year'] = pd.cut(df['year'],\n",
    "                        [1969.9,1979.9,1989.9,1999.9,2009.9,2019.9],\n",
    "                        labels=['1970s_yr','1980s_yr','1990s_yr','2000s_yr','2010s_yr'])  \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate characterising values for each group\n",
    "# i.e. the feature values that are most characteristic\n",
    "# of an attack by each group\n",
    "\n",
    "grp_incs = df['gname'].value_counts()\n",
    "grp_weights = dict()\n",
    "\n",
    "# loop over all columns excluding gname\n",
    "for col in df.drop('gname',axis=1).columns:\n",
    "    # for each group, how many times each unique value appears in this column\n",
    "    grp_cnts = df.groupby('gname')[col].value_counts().unstack(col,fill_value=0)\n",
    "    \n",
    "    # for each unique value in this column, count how many groups have an incident including it\n",
    "    # convert this for tf-idf weight using log(n_groups/count)\n",
    "    w_col = np.log(n_groups/(grp_cnts>0).sum())\n",
    "    \n",
    "    # multiply w_col by no. occurences each column value to get weight for each group\n",
    "    # normalise by no. incidents for that group, so groups can be compared more easily\n",
    "    grp_weights[col] = (grp_cnts*w_col).div(grp_incs,axis=0)\n",
    "\n",
    "# merge unique values for each column in to one large data frame\n",
    "grp_aw = pd.DataFrame(index=top_grps)\n",
    "for key, w_col in grp_weights.items():\n",
    "    grp_aw = pd.merge(grp_aw, w_col, left_index=True, right_index=True,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for grp in top_grps:\n",
    "for grp in grp_incs.head(20).index:    \n",
    "    print(grp_aw.loc[grp].sort_values(ascending=False).head(20))\n",
    "    print('----------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
