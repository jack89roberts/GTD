{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# columns of interest\n",
    "cols_to_extract = ['imonth', 'iyear','iday',\n",
    " 'region_txt','country_txt',\n",
    " 'gname',\n",
    " 'attacktype1_txt',\n",
    " 'success','suicide',\n",
    " 'weaptype1_txt',\n",
    " 'targtype1_txt',\n",
    " 'individual','nperps',\n",
    " 'claimed',\n",
    " 'nkill','nwound',\n",
    " 'propextent_txt',\n",
    " 'ishostkid','hostkidoutcome_txt','ransom']\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel('GTD_0617dist/globalterrorismdb_0617dist.xlsx',\n",
    "                   usecols=cols_to_extract,\n",
    "                   na_values = ['Unknown','-99','-9','Not Applicable'])\n",
    "\n",
    "# replace some values not correctly dealt with by pandas import\n",
    "df.replace(-9,np.nan,inplace=True)\n",
    "df.replace(-99,np.nan,inplace=True)\n",
    "\n",
    "# entries without month or day - treat as 1st January\n",
    "df['imonth'].replace(0,1,inplace=True)\n",
    "df['iday'].replace(0,1,inplace=True)\n",
    "\n",
    "# create a date column, then get rid of the month and day columns\n",
    "df['date']=pd.to_datetime(dict(year=df.iyear, month=df.imonth, day=df.iday)) \n",
    "df.rename(columns={'iyear':'year'}, inplace=True)\n",
    "df.drop(['imonth','iday'],axis=1,inplace=True)\n",
    "\n",
    "# set date as the index\n",
    "df.set_index('date',inplace=True)\n",
    "\n",
    "display(df.head(5))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove events with no group affiliation\n",
    "no_grp = df.gname.isnull() | df.individual\n",
    "with_grp = ~no_grp\n",
    "df = df[with_grp]\n",
    "\n",
    "# don't need the 'individual' column any more\n",
    "df.drop('individual',axis=1,inplace=True)\n",
    "\n",
    "# only keep the top 100 groups with the most incidents\n",
    "n_groups = 100\n",
    "top_grps = df['gname'].value_counts().head(n_groups).index\n",
    "df = df[df.gname.isin(top_grps)]\n",
    "\n",
    "print('Number of events affiliated with individuals or unknown group: ',sum(no_grp))\n",
    "print('Number of events affiliated with a group: ',sum(with_grp))\n",
    "print('Number of events affiliated with top 100 groups: ',len(df))\n",
    "print('')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorise some columns to help feature extraction later\n",
    "\n",
    "# Numeric columns - convert to values for 0, 1, 2-10, and more than 10 \n",
    "conv_numeric = ['nkill','nwound','nperps']\n",
    "\n",
    "for col in conv_numeric:\n",
    "    df[col] = pd.cut(df[col],\n",
    "                        [-0.1,0.9,1.9,10.9,max(df[col])+0.1],\n",
    "                        labels=['0_'+col,'1_'+col,'2to10_'+col,'11+_'+col])\n",
    "\n",
    "# boolean columns - add column suffix\n",
    "conv_bool = ['success','suicide','claimed','property','ishostkid','ransom']\n",
    "\n",
    "for col in conv_bool:\n",
    "    df[col].replace({0:('0_'+col),1:('1_'+col)},inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate characterising values for each group\n",
    "# i.e. the feature values that are most characteristic\n",
    "# of an attack by each group\n",
    "\n",
    "grp_weights = dict()\n",
    "\n",
    "# loop over all columns excluding gname\n",
    "for col in df.drop('gname',axis=1).columns:\n",
    "    # for each group, how many times each unique value appears in this column\n",
    "    grp_cnts = df.groupby('gname')[col].value_counts().unstack(col,fill_value=0)\n",
    "    \n",
    "    # for each unique value in this column, count how many groups have an incident including it\n",
    "    # convert this for tf-idf weight using log(n_groups/count)\n",
    "    w_col = np.log(n_groups/(grp_cnts>0).sum())\n",
    "    \n",
    "    # multiply w_col by no. occurences each column value to get weight for each group\n",
    "    grp_weights[col] = grp_cnts*w_col\n",
    "\n",
    "    # print some values for the Taliban\n",
    "    print(grp_weights[col].loc['Taliban'].sort_values(ascending=False).head(2))\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "#grpw_all = pd.merge(grp_weights['country_txt'],grp_weights['year'],left_index=True,right_index=True)\n",
    "#\n",
    "#for grp in top_grps:\n",
    "#    print(grpw_all.loc[grp].sort_values(ascending=False).head(3))\n",
    "#    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
