{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Features Associated with Groups and First Model Attempts\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# columns of interest\n",
    "cols_to_extract = ['eventid', 'iyear',\n",
    " 'country_txt','gname','attacktype1_txt',\n",
    " 'success','suicide',\n",
    " 'weaptype1_txt','weapsubtype1_txt',\n",
    " 'targtype1_txt','targsubtype1_txt',\n",
    " 'individual','nperps','claimed',\n",
    " 'nkill','nwound',\n",
    " 'property','propextent_txt',\n",
    " 'ishostkid','nhostkid','hostkidoutcome_txt','ransom']\n",
    "\n",
    "# Load data\n",
    "df = pd.read_excel('GTD_0617dist/globalterrorismdb_0617dist.xlsx',\n",
    "                   index='eventid',\n",
    "                   usecols=cols_to_extract,\n",
    "                   na_values = ['Unknown','-99','-9','Not Applicable'])\n",
    "\n",
    "# setting index in read statement doesn't seem to work, so do it here\n",
    "df.set_index('eventid',inplace=True) \n",
    "\n",
    "# replace unwanted _txt suffix from column names\n",
    "df.columns = df.columns.str.replace('_txt','')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract events associated with groups of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove events with no group affiliation\n",
    "no_grp = df.gname.isnull() | df.individual\n",
    "with_grp = ~no_grp\n",
    "df = df[with_grp]\n",
    "\n",
    "# don't need the 'individual' column any more\n",
    "df.drop('individual',axis=1,inplace=True)\n",
    "\n",
    "# only keep the top n groups with the most incidents\n",
    "n_groups = 50 #for all groups: df['gname'].nunique()\n",
    "\n",
    "top_grps = df['gname'].value_counts().head(n_groups).index\n",
    "df = df[df.gname.isin(top_grps)]\n",
    "\n",
    "print('Number of events affiliated with individuals or unknown group: ',sum(no_grp))\n",
    "print('Number of events affiliated with a group: ',sum(with_grp))\n",
    "print('Number of events affiliated with top {} groups: {}'.format(n_groups,len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify some unwanted columns and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace some values not correctly dealt with by pandas import\n",
    "df.replace(-9,np.nan,inplace=True)\n",
    "df.replace(-99,np.nan,inplace=True)\n",
    "\n",
    "# rename year column\n",
    "df.rename(columns={'iyear':'year'}, inplace=True)\n",
    "\n",
    "# If no claimed info - treat as not claimed\n",
    "df['claimed'].fillna(0,inplace=True)\n",
    "\n",
    "# remove some values that don't give useful information\n",
    "df['weaptype1'].replace('Other',np.nan,inplace=True)\n",
    "\n",
    "df['weapsubtype1'].replace(['Unknown Gun Type', 'Unknown Explosive Type',\n",
    "                                'Other Explosive Type', 'Unknown Weapon Type',\n",
    "                                'Other Gun Type'], np.nan, inplace=True)\n",
    "\n",
    "df['targtype1'].replace('Other',np.nan,inplace=True)\n",
    "\n",
    "df['targsubtype1'].replace(['Other Personnel', 'Other (including online news agencies)', 'Other Facility'],\n",
    "                               np.nan,inplace=True)\n",
    "\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorise some columns to reduce no. features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns - convert to values for 0, 1, 2-10, and more than 10 \n",
    "conv_numeric = ['nkill','nwound','nperps','nhostkid']\n",
    "\n",
    "for col in conv_numeric:\n",
    "    df[col] = pd.cut(df[col],\n",
    "                        [-0.1,0.9,1.9,10.9,max(df[col])+0.1],\n",
    "                        labels=['0','1','2to10','11'])\n",
    "\n",
    "# boolean columns - convert to yes/no to help identification in dummy variables later\n",
    "conv_bool = ['success','suicide','claimed','property','ishostkid','ransom']\n",
    "\n",
    "for col in conv_bool:\n",
    "    df[col].replace({0:'no',1:'yes'},inplace=True)\n",
    "\n",
    "# bin year in to decades\n",
    "df['year'] = pd.cut(df['year'],\n",
    "                        [1969.9,1979.9,1989.9,1999.9,2009.9,2019.9],\n",
    "                        labels=['1970s','1980s','1990s','2000s','2010s'])  \n",
    "\n",
    "display(df.head())\n",
    "\n",
    "# warning message below r.e. empty bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# labels\n",
    "y = df['gname']\n",
    "display(y.head())\n",
    "\n",
    "# features\n",
    "X = df.drop('gname',axis=1)\n",
    "display(X.head())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)\n",
    "print('Train: X shape =',X_train.shape,', Y shape=',y_train.shape)\n",
    "print('Test: X shape =',X_test.shape,', Y shape=',y_test.shape)\n",
    "\n",
    "# make some combined data frames with both labels and features. Useful later.\n",
    "df_train = X_train.copy()\n",
    "df_train['gname'] =  y_train\n",
    "\n",
    "df_test = X_test.copy()\n",
    "df_test['gname'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy variables for Each Category Value\n",
    "\n",
    "Gives a bool column for each unique value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "# do on full dataset first to make sure same columns in test and train\n",
    "y_dum = pd.get_dummies(y)\n",
    "y_dum_train = y_dum.loc[y_train.index]\n",
    "y_dum_test = y_dum.loc[y_test.index]\n",
    "\n",
    "display(y_dum_train.head())\n",
    "\n",
    "# features\n",
    "# do on full dataset first to make sure same columns in test and train\n",
    "X_dum = pd.get_dummies(X)\n",
    "X_dum_train = X_dum.loc[X_train.index]\n",
    "X_dum_test = X_dum.loc[X_test.index]\n",
    "\n",
    "# NaN values in test data can destroy predictions so remove them\n",
    "X_dum_test.fillna(0,inplace=True) \n",
    "\n",
    "display(X_dum_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Characterising Values for each Group\n",
    "i.e. the feature values that are most characteristic of an attack by each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. incidents associated with each group\n",
    "grp_incs = y.value_counts()\n",
    "\n",
    "# add group name column to the data frame of dummies\n",
    "df_dum_train = X_dum_train.copy()\n",
    "df_dum_train['gname'] =  y_train\n",
    "\n",
    "# loop over all columns excluding gname\n",
    "col_tfidf = dict()\n",
    "\n",
    "for col in df_dum_train.drop('gname',axis=1).columns:\n",
    "    # for each group, how many times this unique value appears\n",
    "    grp_cnts = df_dum_train.groupby('gname')[col].sum()\n",
    "    \n",
    "    # count how many groups have an incident including this unique value\n",
    "    # convert this for tf-idf weight using log(n_groups/count)\n",
    "    if (grp_cnts>0).sum()==0:\n",
    "        print('Warning: No instances of',col)\n",
    "        \n",
    "    w_col = np.log(n_groups/((grp_cnts>0).sum()))\n",
    "    \n",
    "    # multiply w_col by no. occurences each column value to get weight for each group\n",
    "    col_tfidf[col] = (grp_cnts*w_col)\n",
    "    \n",
    "# merge unique values for each column in to one large data frame\n",
    "w_tfidf = pd.DataFrame(col_tfidf,index=top_grps)\n",
    "\n",
    "# get rid of NaN weights\n",
    "w_tfidf.fillna(0,inplace=True)\n",
    "\n",
    "w_tfidf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Top n Features for Top m Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_print_grp=10\n",
    "n_print_feat=5\n",
    "\n",
    "for grp in grp_incs.head(n_print_grp).index:    \n",
    "    print(w_tfidf.loc[grp].sort_values(ascending=False).head(n_print_feat))\n",
    "    print('----------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Using tf-idf Type Weights Derived Above\n",
    "NB: weights above calculated on all data. Should be only on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract neg_scale*weight for features not present in event\n",
    "# but present in group\n",
    "neg_scale = 0.25 \n",
    "\n",
    "# matrix multiply test events by group weights for each feature\n",
    "tfidf_events = pd.DataFrame(np.inner(X_dum_test,w_tfidf),index=X_dum_test.index,columns=w_tfidf.index)\n",
    "\n",
    "# subtract contribution of negative cases\n",
    "tfidf_events = tfidf_events - neg_scale*pd.DataFrame(np.inner(X_dum_test.replace({0:1,1:0}),w_tfidf),index=X_dum_test.index,columns=w_tfidf.index)\n",
    "\n",
    "tfidf_pred = pd.DataFrame({'gname':y_test,'pred':tfidf_events.idxmax(axis=1)})\n",
    "tfidf_pred['true'] = tfidf_pred.gname == tfidf_pred.pred\n",
    "\n",
    "# stats on accuracy of model overall and per group\n",
    "print('overall accuracy',sum(tfidf_pred.true)/len(tfidf_pred))\n",
    "\n",
    "# calculate metrics\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "\n",
    "print('precision',precision_score(tfidf_pred.gname, tfidf_pred.pred, labels=top_grps,average='micro'))\n",
    "print('recall',recall_score(tfidf_pred.gname, tfidf_pred.pred, labels=top_grps,average='micro'))\n",
    "print('accuracy',accuracy_score(tfidf_pred.gname, tfidf_pred.pred))\n",
    "print('confusion matrix (top 20 grps):')\n",
    "cmatrix = confusion_matrix(tfidf_pred.gname, tfidf_pred.pred,labels=top_grps)        \n",
    "display(pd.DataFrame(cmatrix).iloc[:20,:20])\n",
    "\n",
    "print('grp13: ',top_grps[13])\n",
    "print('grp6: ',top_grps[6])\n",
    "print('----------------------------')\n",
    "print('grp14: ',top_grps[14])\n",
    "print('grp11: ',top_grps[11])\n",
    "print('----------------------------')\n",
    "print('grp19: ',top_grps[19])\n",
    "print('grp17: ',top_grps[17])\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==========================')\n",
    "print('Frequent groups with incorrect predictions')\n",
    "print('==========================')\n",
    "display(tfidf_pred[(~tfidf_pred.true)].gname.value_counts().head(10))\n",
    "\n",
    "print('==========================')\n",
    "print('Incorrect predictions')\n",
    "print('==========================')\n",
    "display(tfidf_pred[(~tfidf_pred.true)].pred.value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Classifier to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import average_precision_score, accuracy_score\n",
    "\n",
    "model=OneVsRestClassifier(LinearSVC(random_state=0)).fit(X_dum_train.fillna(0), y_dum_train.fillna(0))\n",
    "\n",
    "y_svc_pred = model.predict(X_dum_test.fillna(0))\n",
    "\n",
    "print('Accuracy score:',accuracy_score(y_dum_test,y_svc_pred))\n",
    "print('Precision score:',average_precision_score(y_dum_test,y_svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the Results of the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract group for each event in test data\n",
    "#y_test = y_test.stack()\n",
    "#y_test = y_test[y_test>0].index.get_level_values(1)\n",
    "\n",
    "# extract prediction for each event in test data\n",
    "labels_svc_pred = y_dum_test.columns[y_svc_pred.argmax(axis=1)]\n",
    "\n",
    "# create a data frame of labels and predictions\n",
    "labels_svc = pd.DataFrame({'true':y_test.values, 'pred':labels_svc_pred.values})\n",
    "\n",
    "# was the predcition correct?\n",
    "labels_svc['correct'] = labels_svc['pred']==labels_svc['true']\n",
    "\n",
    "# labelled correctly / total events\n",
    "frac_true_svc = (labels_svc.loc[labels_svc.correct,'true'].value_counts()/labels_svc['true'].value_counts()).sort_values(ascending=False)\n",
    "\n",
    "# predicted correctly / predicted total\n",
    "frac_pred_svc = (labels_svc.loc[labels_svc.correct,'pred'].value_counts()/labels_svc['pred'].value_counts()).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "print('-------------------------------------------')\n",
    "print('Groups commonly labelled incorrectly:')\n",
    "print('-------------------------------------------')\n",
    "display(labels_svc.loc[~labels_svc.correct,'true'].value_counts().head(5))\n",
    "display(frac_true_svc.tail(5).sort_values())\n",
    "print('-------------------------------------------')\n",
    "print('Common incorrect predictions:')\n",
    "print('-------------------------------------------')\n",
    "display(labels_svc.loc[~labels_svc.correct,'pred'].value_counts().head(5))\n",
    "display(frac_pred_svc.tail(5).sort_values())\n",
    "print('-------------------------------------------')\n",
    "print('Groups commonly labelled correctly:')\n",
    "print('-------------------------------------------')\n",
    "display(labels_svc.loc[labels_svc.correct,'true'].value_counts().head(5))\n",
    "display(frac_true_svc.head(5))\n",
    "print('-------------------------------------------')\n",
    "print('Common correct predictions:')\n",
    "print('-------------------------------------------')\n",
    "display(labels_svc.loc[labels_svc.correct,'pred'].value_counts().head(5))\n",
    "display(frac_pred_svc.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abu Sayyaf Group (ASG): Frequently Predicted Wrongly\n",
    "\n",
    "A look at some of the features of ASG events, and the groups that are often mistaken for ASG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=============================')\n",
    "print('Abu Sayyaf Group (ASG)')\n",
    "print('=============================')\n",
    "asg=df[df.gname=='Abu Sayyaf Group (ASG)']\n",
    "display(asg['country'].value_counts())\n",
    "\n",
    "print('=============================')\n",
    "print('Philippines')\n",
    "print('=============================')\n",
    "print(df[df.country == 'Philippines']['gname'].value_counts())\n",
    "\n",
    "print('=============================')\n",
    "print('Malaysia')\n",
    "print('=============================')\n",
    "print(df[df.country == 'Malaysia']['gname'].value_counts())\n",
    "\n",
    "print('================================================')\n",
    "print('Regularly Mistaken for Abu Sayyaf Group (ASG)')\n",
    "print('================================================')\n",
    "print(labels_svc.loc[(~labels_svc.correct) & (labels_svc.pred=='Abu Sayyaf Group (ASG)')].true.value_counts().head(10))\n",
    "\n",
    "asg_w = w_tfidf.loc['Abu Sayyaf Group (ASG)']\n",
    "farc_w = w_tfidf.loc['Revolutionary Armed Forces of Colombia (FARC)']\n",
    "asgfarc = pd.DataFrame({'Abu Sayyaf Group (ASG)':asg_w, 'Revolutionary Armed Forces of Colombia (FARC)':farc_w})\n",
    "asgfarc['diff'] = asgfarc['Abu Sayyaf Group (ASG)']-asgfarc['Revolutionary Armed Forces of Colombia (FARC)']\n",
    "\n",
    "print('================================================')\n",
    "print('Features More Common in ASG than FARC')\n",
    "print('================================================')\n",
    "display(asgfarc.sort_values('diff').tail(5).sort_values(by='diff',ascending=False))\n",
    "\n",
    "print('=========================================================================')\n",
    "print('Features More Common FARC than ASG')\n",
    "print('=========================================================================')\n",
    "display(asgfarc.sort_values('diff').head(5))\n",
    "\n",
    "print('=========================================================================')\n",
    "print('Features Similar in Both')\n",
    "print('=========================================================================')\n",
    "inboth = (asgfarc['Abu Sayyaf Group (ASG)']>0.005) & (asgfarc['Revolutionary Armed Forces of Colombia (FARC)']>0.005)\n",
    "display(abs(asgfarc.loc[inboth]).sort_values('diff'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries of ASG Predicted Events\n",
    "\n",
    "ASG often predicted for events in countries they were never active in. Suggests country should be weighted much more heavily? Try much simpler model using only year, latitude, longitude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the predicted labels columns to the test_events df\n",
    "test_events_svc = pd.merge(df_test, \n",
    "                       pd.DataFrame({'pred':labels_svc_pred},index=df_test.index),\n",
    "                       left_index=True,right_index=True)\n",
    "\n",
    "test_events_svc['true'] = test_events_svc['gname']==test_events_svc['pred']\n",
    "\n",
    "print('======================================================================')\n",
    "print('Countries of Events Incorrectly Predicted as Abu Sayyaf Group (ASG)')\n",
    "print('======================================================================')\n",
    "print(test_events_svc[(test_events_svc.pred=='Abu Sayyaf Group (ASG)') & (~test_events_svc.true)]['country'].unique())\n",
    "print('======================================================================')\n",
    "print('Countries Where Abu Sayyaf Group (ASG) Carried Out Attacks')\n",
    "print('======================================================================')\n",
    "print(df[df.gname=='Abu Sayyaf Group (ASG)']['country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability each feature value\n",
    "p_x = X_dum_train.sum()/len(X_dum_train)\n",
    "display(p_x.sort_values(ascending=False).head())\n",
    "\n",
    "# probability each group y\n",
    "grp_incs_train = y_train.value_counts()\n",
    "p_y = grp_incs_train/len(X_dum_train)\n",
    "display(p_y.head())\n",
    "\n",
    "# probability each feature value, given group y\n",
    "p_xgy = df_dum_train.groupby('gname').sum()\n",
    "p_xgy = p_xgy.divide(grp_incs_train, axis=0)\n",
    "display(p_xgy.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series to store results in\n",
    "y_baies = pd.Series(index=X_dum_test.index)\n",
    "\n",
    "for event in X_dum_test.index:\n",
    "    # likelihood for each feature given each group\n",
    "    probs = X_dum_test.loc[event]*p_xgy\n",
    "    \n",
    "    # multiply likelihoods for each feature\n",
    "    probs=probs.T\n",
    "    probs=probs[probs.sum(axis=1)>0]\n",
    "    probs=probs.product().multiply(p_y)\n",
    "    \n",
    "    # normalise\n",
    "    #probs = probs/probs.sum()\n",
    "    \n",
    "    # store group with max likelihood\n",
    "    y_baies[event]=probs.idxmax(axis=1)\n",
    "    \n",
    "df_baies = pd.DataFrame({'gname':y_test,'pred':y_baies})\n",
    "df_baies['true'] = df_baies.gname == df_baies.pred\n",
    "\n",
    "print('overall accuracy',sum(df_baies.true)/len(df_baies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('precision',precision_score(df_baies.gname, df_baies.pred, labels=top_grps,average='micro'))\n",
    "print('recall',recall_score(df_baies.gname, df_baies.pred, labels=top_grps,average='micro'))\n",
    "print('accuracy',accuracy_score(df_baies.gname, df_baies.pred))\n",
    "print('confusion matrix (top 20 grps):')\n",
    "cmatrix = confusion_matrix(df_baies.gname, df_baies.pred,labels=top_grps)        \n",
    "display(pd.DataFrame(cmatrix).iloc[:20,:20])\n",
    "\n",
    "print('grp13: ',top_grps[13])\n",
    "print('grp6: ',top_grps[6])\n",
    "print('----------------------------')\n",
    "print('grp14: ',top_grps[14])\n",
    "print('grp11: ',top_grps[11])\n",
    "print('----------------------------')\n",
    "print('grp19: ',top_grps[19])\n",
    "print('grp17: ',top_grps[17])\n",
    "print('----------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
